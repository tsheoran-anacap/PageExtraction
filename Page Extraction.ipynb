{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246f00e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: pdfs\\1696673572082.pdf\n",
      "Downloaded: pdfs\\1696595155026.PDF\n",
      "Downloaded: pdfs\\1696654632776.pdf\n",
      "Downloaded: pdfs\\1696327038844.pdf\n",
      "Downloaded: pdfs\\1696135649816.pdf\n",
      "Downloaded: pdfs\\1695827627274.pdf\n",
      "Downloaded: pdfs\\1695728274798.pdf\n",
      "Downloaded: pdfs\\1695456916964.pdf\n",
      "Downloaded: pdfs\\1694694389099.pdf\n",
      "Downloaded: pdfs\\1694428072042.pdf\n",
      "Downloaded: pdfs\\1694428024413.pdf\n",
      "Downloaded: pdfs\\1693992032270.pdf\n",
      "Downloaded: pdfs\\1693885766733.pdf\n",
      "Downloaded: pdfs\\1693916577201.pdf\n",
      "Downloaded: pdfs\\1693827231343.pdf\n",
      "Downloaded: pdfs\\1693308807687.pdf\n",
      "Downloaded: pdfs\\1692890379610.pdf\n",
      "Downloaded: pdfs\\1692890118636.pdf\n",
      "Downloaded: pdfs\\1691757155740.pdf\n",
      "Downloaded: pdfs\\1691752873496.pdf\n",
      "Downloaded: pdfs\\1691668695506.pdf\n",
      "Downloaded: pdfs\\1691580430610.pdf\n",
      "Downloaded: pdfs\\1691492595118.pdf\n",
      "Downloaded: pdfs\\1691409221863.pdf\n",
      "Downloaded: pdfs\\1691160024690.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin, parse_qs\n",
    "\n",
    "# Function to extract URLs from iframe tags in a given page\n",
    "def extract_iframe_urls(page_url):\n",
    "    response = requests.get(page_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        iframe_tags = soup.find_all('iframe')\n",
    "        \n",
    "        iframe_urls = []\n",
    "        for iframe_tag in iframe_tags:\n",
    "            src = iframe_tag.get('src')\n",
    "            if src:\n",
    "                iframe_urls.append(urljoin(page_url, src))\n",
    "\n",
    "        return iframe_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page: {page_url}. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Function to filter out URLs with .pdf extension\n",
    "def filter_pdf_urls(urls):\n",
    "    pdf_urls = [url for url in urls if url.lower().endswith('.pdf')]\n",
    "    return pdf_urls\n",
    "\n",
    "# Function to extract the \"file\" query parameter from a URL\n",
    "def extract_file_param(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    if 'file' in query_params:\n",
    "        return query_params['file'][0]\n",
    "    return None\n",
    "\n",
    "# Function to download and save a PDF from a given URL\n",
    "def download_pdf(pdf_url, save_folder):\n",
    "    filename = extract_file_param(pdf_url)\n",
    "    response = requests.get(filename)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Extract the filename from the \"file\" query parameter\n",
    "        if pdf_url:\n",
    "            # Sanitize the filename (remove any path traversal)\n",
    "            filename = os.path.basename(filename)\n",
    "            filename = os.path.join(save_folder, filename)\n",
    "            \n",
    "            # Save the PDF to the specified folder\n",
    "            with open(filename, 'wb') as pdf_file:\n",
    "                pdf_file.write(response.content)\n",
    "            print(f\"Downloaded: {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to extract 'file' query parameter from URL: {pdf_url}\")\n",
    "    else:\n",
    "        print(f\"Failed to download PDF: {pdf_url}. Status code: {response.status_code}\")\n",
    "\n",
    "# URL of the web page you want to start from\n",
    "start_url = 'https://sebi.gov.in/sebiweb/home/HomeAction.do?doListing=yes&sid=1&ssid=7&smid=0' # Replace with the URL of your choice\n",
    "save_folder = 'pdfs'  # Replace with the path to your desired save folder\n",
    "\n",
    "# Create the save folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# Send an HTTP GET request to the start URL\n",
    "start_response = requests.get(start_url)\n",
    "\n",
    "# Check if the request to the start URL was successful (status code 200)\n",
    "if start_response.status_code == 200:\n",
    "    # Parse the HTML content of the start page using BeautifulSoup\n",
    "    start_soup = BeautifulSoup(start_response.text, 'html.parser')\n",
    "    \n",
    "    # Find all valid URLs within <a> tags on the start page\n",
    "    valid_urls = []\n",
    "    a_tags = start_soup.find_all('a')\n",
    "    for a_tag in a_tags:\n",
    "        href = a_tag.get('href')\n",
    "        if href and urlparse(href).scheme and (\"javascript\" not in href):\n",
    "            valid_urls.append(href)\n",
    "\n",
    "    # Loop over the valid URLs and extract iframe URLs from each page\n",
    "    for valid_url in valid_urls:\n",
    "        iframe_urls = extract_iframe_urls(valid_url)\n",
    "        \n",
    "        # Filter out URLs with .pdf extension\n",
    "        pdf_urls = filter_pdf_urls(iframe_urls)\n",
    "        \n",
    "        # Download and save the PDFs to the folder\n",
    "        for pdf_url in pdf_urls:\n",
    "            download_pdf(pdf_url, save_folder)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the start page: {start_url}. Status code: {start_response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb4b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
